{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing class 'Cerscospora' in 'train'...\n",
      "🔹 Found 6144 original images.\n",
      "🔹 Generating 23856 augmented images.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 128\u001b[0m\n\u001b[0;32m    125\u001b[0m aug_image \u001b[38;5;241m=\u001b[39m (aug_image \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m255\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39muint8)\n\u001b[0;32m    127\u001b[0m save_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(class_output_path, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maug_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maug_count\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 128\u001b[0m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43maug_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_RGB2BGR\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    130\u001b[0m aug_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m aug_count \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m num_needed:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "# Paths (Update if needed)\n",
    "input_dir = r\"E:\\CLD_project\\CLD_dataset_split\"  # Your dataset with train/val/test\n",
    "output_dir = r\"E:\\CLD_project\\CLD_dataset_split_augmented\"  # Augmented dataset location\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Target number of images per class (Adjust if needed)\n",
    "TARGET_IMAGES = 30000\n",
    "\n",
    "# ✅ Augmentation Functions\n",
    "def augment_brightness(image):\n",
    "    return np.clip(tf.image.adjust_brightness(image, delta=random.uniform(-0.4, 0.4)).numpy(), 0, 1)\n",
    "\n",
    "def augment_contrast(image):\n",
    "    return np.clip(tf.image.adjust_contrast(image, contrast_factor=random.uniform(0.9, 1.2)).numpy(), 0, 1)\n",
    "\n",
    "def augment_flip(image):\n",
    "    return np.flip(image, axis=1)\n",
    "\n",
    "def augment_rotate(image):\n",
    "    h, w, _ = image.shape\n",
    "    angle = np.random.uniform(-30, 30)\n",
    "    M = cv2.getRotationMatrix2D((w / 2, h / 2), angle, 1)\n",
    "    return cv2.warpAffine(image, M, (w, h))\n",
    "\n",
    "def augment_shift(image):\n",
    "    h, w, _ = image.shape\n",
    "    w_shift = np.random.uniform(-0.2, 0.2) * w\n",
    "    h_shift = np.random.uniform(-0.2, 0.2) * h\n",
    "    M_shift = np.float32([[1, 0, w_shift], [0, 1, h_shift]])\n",
    "    return cv2.warpAffine(image, M_shift, (w, h))\n",
    "\n",
    "def augment_zoom(image):\n",
    "    zoom_factor = np.random.uniform(0.8, 1.2)\n",
    "    new_size = int(224 * zoom_factor)\n",
    "    zoomed = cv2.resize(image, (new_size, new_size))\n",
    "    return cv2.resize(zoomed, (224, 224))\n",
    "\n",
    "def augment_cover_part(image):\n",
    "    h, w, _ = image.shape\n",
    "    mask_size = random.randint(int(h * 0.3), int(h * 0.3))\n",
    "    x, y = random.randint(0, w - mask_size), random.randint(0, h - mask_size)\n",
    "    image[y:y+mask_size, x:x+mask_size, :] = 0\n",
    "    return image\n",
    "\n",
    "def augment_gaussian_noise(image):\n",
    "    noise = np.random.normal(0, random.uniform(10, 30), image.shape).astype(np.float32) / 255.0\n",
    "    return np.clip(image + noise, 0, 1)\n",
    "\n",
    "def augment_salt_pepper_noise(image, salt_prob=0.2, pepper_prob=0.2):\n",
    "    noisy_image = image.copy()\n",
    "    h, w, c = image.shape\n",
    "    num_salt, num_pepper = int(salt_prob * h * w), int(pepper_prob * h * w)\n",
    "    salt_coords = [np.random.randint(0, i, num_salt) for i in [h, w]]\n",
    "    pepper_coords = [np.random.randint(0, i, num_pepper) for i in [h, w]]\n",
    "    noisy_image[salt_coords[0], salt_coords[1], :] = 1.0\n",
    "    noisy_image[pepper_coords[0], pepper_coords[1], :] = 0.0\n",
    "    return noisy_image\n",
    "\n",
    "AUGMENTATIONS = [\n",
    "    augment_brightness, augment_contrast, augment_flip,\n",
    "    augment_rotate, augment_shift, augment_zoom,\n",
    "    augment_cover_part, augment_gaussian_noise, augment_salt_pepper_noise\n",
    "]\n",
    "\n",
    "# ✅ Process 'train' and 'val' (Skip 'test')\n",
    "for split in ['train', 'val']:  # Apply only to train and val\n",
    "    split_input_path = os.path.join(input_dir, split)\n",
    "    split_output_path = os.path.join(output_dir, split)\n",
    "    os.makedirs(split_output_path, exist_ok=True)\n",
    "\n",
    "    for class_name in os.listdir(split_input_path):\n",
    "        class_input_path = os.path.join(split_input_path, class_name)\n",
    "        class_output_path = os.path.join(split_output_path, class_name)\n",
    "        os.makedirs(class_output_path, exist_ok=True)\n",
    "\n",
    "        print(f\"Processing class '{class_name}' in '{split}'...\")\n",
    "\n",
    "        images = [img for img in os.listdir(class_input_path) if img.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "        num_original = len(images)\n",
    "\n",
    "        if num_original == 0:\n",
    "            print(f\"⚠️ Skipping '{class_name}' (no images found).\")\n",
    "            continue\n",
    "\n",
    "        print(f\"🔹 Found {num_original} original images.\")\n",
    "\n",
    "        # Copy original images\n",
    "        for image_name in images:\n",
    "            image_path = os.path.join(class_input_path, image_name)\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is None:\n",
    "                continue\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image = cv2.resize(image, (224, 224))\n",
    "\n",
    "            save_path = os.path.join(class_output_path, f\"orig_{image_name}\")\n",
    "            cv2.imwrite(save_path, cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "        num_needed = TARGET_IMAGES - num_original\n",
    "        print(f\"🔹 Generating {num_needed} augmented images.\")\n",
    "\n",
    "        aug_count = 0\n",
    "        while aug_count < num_needed:\n",
    "            for image_name in images:\n",
    "                image_path = os.path.join(class_input_path, image_name)\n",
    "                image = cv2.imread(image_path)\n",
    "                if image is None:\n",
    "                    continue\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                image = cv2.resize(image, (224, 224))\n",
    "\n",
    "                num_augmentations = random.randint(1, 3)\n",
    "                chosen_augmentations = random.sample(AUGMENTATIONS, num_augmentations)\n",
    "\n",
    "                aug_image = image.astype(np.float32) / 255.0\n",
    "                for aug_func in chosen_augmentations:\n",
    "                    aug_image = aug_func(aug_image)\n",
    "\n",
    "                aug_image = (aug_image * 255).astype(np.uint8)\n",
    "\n",
    "                save_path = os.path.join(class_output_path, f\"aug_{aug_count}_{image_name}\")\n",
    "                cv2.imwrite(save_path, cv2.cvtColor(aug_image, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "                aug_count += 1\n",
    "                if aug_count >= num_needed:\n",
    "                    break\n",
    "\n",
    "        print(f\"✅ Class '{class_name}' in '{split}' now contains {TARGET_IMAGES} images.\")\n",
    "\n",
    "print(\"🎉 Data augmentation for train and val complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing class 'Cerscospora' in 'train'...\n",
      "🔹 Found 6144 original images.\n",
      "🔹 Generating 18856 augmented images.\n",
      "✅ Class 'Cerscospora' in 'train' now contains 25000 images.\n",
      "Processing class 'Healthy' in 'train'...\n",
      "🔹 Found 15187 original images.\n",
      "🔹 Generating 9813 augmented images.\n",
      "✅ Class 'Healthy' in 'train' now contains 25000 images.\n",
      "Processing class 'Leaf rust' in 'train'...\n",
      "🔹 Found 6668 original images.\n",
      "🔹 Generating 18332 augmented images.\n",
      "✅ Class 'Leaf rust' in 'train' now contains 25000 images.\n",
      "Processing class 'Miner' in 'train'...\n",
      "🔹 Found 13582 original images.\n",
      "🔹 Generating 11418 augmented images.\n",
      "✅ Class 'Miner' in 'train' now contains 25000 images.\n",
      "Processing class 'Phoma' in 'train'...\n",
      "🔹 Found 5256 original images.\n",
      "🔹 Generating 19744 augmented images.\n",
      "✅ Class 'Phoma' in 'train' now contains 25000 images.\n",
      "Processing class 'Cerscospora' in 'val'...\n",
      "🔹 Found 768 original images.\n",
      "🔹 Generating 4232 augmented images.\n",
      "✅ Class 'Cerscospora' in 'val' now contains 5000 images.\n",
      "Processing class 'Healthy' in 'val'...\n",
      "🔹 Found 1898 original images.\n",
      "🔹 Generating 3102 augmented images.\n",
      "✅ Class 'Healthy' in 'val' now contains 5000 images.\n",
      "Processing class 'Leaf rust' in 'val'...\n",
      "🔹 Found 833 original images.\n",
      "🔹 Generating 4167 augmented images.\n",
      "✅ Class 'Leaf rust' in 'val' now contains 5000 images.\n",
      "Processing class 'Miner' in 'val'...\n",
      "🔹 Found 1697 original images.\n",
      "🔹 Generating 3303 augmented images.\n",
      "✅ Class 'Miner' in 'val' now contains 5000 images.\n",
      "Processing class 'Phoma' in 'val'...\n",
      "🔹 Found 657 original images.\n",
      "🔹 Generating 4343 augmented images.\n",
      "✅ Class 'Phoma' in 'val' now contains 5000 images.\n",
      "🎉 Data augmentation for train and val complete!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "# Paths\n",
    "input_dir = r\"E:\\CLD_project\\CLD_dataset_split\"  # Your split dataset\n",
    "output_dir = r\"E:\\CLD_project\\CLD_dataset_split_augmented\"  # Augmented dataset location\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# ✅ Define Target Image Counts\n",
    "TARGET_IMAGES = {\n",
    "    \"train\": 25000,  # Each class in train will have 25,000 images\n",
    "    \"val\": 5000,     # Each class in val will have 5,000 images\n",
    "}\n",
    "\n",
    "# ✅ Augmentation Functions\n",
    "def augment_brightness(image):\n",
    "    return np.clip(tf.image.adjust_brightness(image, delta=random.uniform(-0.4, 0.4)).numpy(), 0, 1)\n",
    "\n",
    "def augment_contrast(image):\n",
    "    return np.clip(tf.image.adjust_contrast(image, contrast_factor=random.uniform(0.9, 1.2)).numpy(), 0, 1)\n",
    "\n",
    "def augment_flip(image):\n",
    "    return np.flip(image, axis=1)\n",
    "\n",
    "def augment_rotate(image):\n",
    "    h, w, _ = image.shape\n",
    "    angle = np.random.uniform(-30, 30)\n",
    "    M = cv2.getRotationMatrix2D((w / 2, h / 2), angle, 1)\n",
    "    return cv2.warpAffine(image, M, (w, h))\n",
    "\n",
    "def augment_shift(image):\n",
    "    h, w, _ = image.shape\n",
    "    w_shift = np.random.uniform(-0.2, 0.2) * w\n",
    "    h_shift = np.random.uniform(-0.2, 0.2) * h\n",
    "    M_shift = np.float32([[1, 0, w_shift], [0, 1, h_shift]])\n",
    "    return cv2.warpAffine(image, M_shift, (w, h))\n",
    "\n",
    "def augment_zoom(image):\n",
    "    zoom_factor = np.random.uniform(0.8, 1.2)\n",
    "    new_size = int(224 * zoom_factor)\n",
    "    zoomed = cv2.resize(image, (new_size, new_size))\n",
    "    return cv2.resize(zoomed, (224, 224))\n",
    "\n",
    "def augment_cover_part(image):\n",
    "    h, w, _ = image.shape\n",
    "    mask_size = random.randint(int(h * 0.3), int(h * 0.3))\n",
    "    x, y = random.randint(0, w - mask_size), random.randint(0, h - mask_size)\n",
    "    image[y:y+mask_size, x:x+mask_size, :] = 0\n",
    "    return image\n",
    "\n",
    "def augment_gaussian_noise(image):\n",
    "    noise = np.random.normal(0, random.uniform(10, 30), image.shape).astype(np.float32) / 255.0\n",
    "    return np.clip(image + noise, 0, 1)\n",
    "\n",
    "def augment_salt_pepper_noise(image, salt_prob=0.2, pepper_prob=0.2):\n",
    "    noisy_image = image.copy()\n",
    "    h, w, c = image.shape\n",
    "    num_salt, num_pepper = int(salt_prob * h * w), int(pepper_prob * h * w)\n",
    "    salt_coords = [np.random.randint(0, i, num_salt) for i in [h, w]]\n",
    "    pepper_coords = [np.random.randint(0, i, num_pepper) for i in [h, w]]\n",
    "    noisy_image[salt_coords[0], salt_coords[1], :] = 1.0\n",
    "    noisy_image[pepper_coords[0], pepper_coords[1], :] = 0.0\n",
    "    return noisy_image\n",
    "\n",
    "AUGMENTATIONS = [\n",
    "    augment_brightness, augment_contrast, augment_flip,\n",
    "    augment_rotate, augment_shift, augment_zoom,\n",
    "    augment_cover_part, augment_gaussian_noise, augment_salt_pepper_noise\n",
    "]\n",
    "\n",
    "# ✅ Process 'train' and 'val' (Skip 'test')\n",
    "for split in [\"train\", \"val\"]:  # Apply augmentation only to train and val\n",
    "    split_input_path = os.path.join(input_dir, split)\n",
    "    split_output_path = os.path.join(output_dir, split)\n",
    "    os.makedirs(split_output_path, exist_ok=True)\n",
    "\n",
    "    target_count = TARGET_IMAGES[split]\n",
    "\n",
    "    for class_name in os.listdir(split_input_path):\n",
    "        class_input_path = os.path.join(split_input_path, class_name)\n",
    "        class_output_path = os.path.join(split_output_path, class_name)\n",
    "        os.makedirs(class_output_path, exist_ok=True)\n",
    "\n",
    "        print(f\"Processing class '{class_name}' in '{split}'...\")\n",
    "\n",
    "        images = [img for img in os.listdir(class_input_path) if img.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "        num_original = len(images)\n",
    "\n",
    "        if num_original == 0:\n",
    "            print(f\"⚠️ Skipping '{class_name}' (no images found).\")\n",
    "            continue\n",
    "\n",
    "        print(f\"🔹 Found {num_original} original images.\")\n",
    "\n",
    "        # Copy original images\n",
    "        for image_name in images:\n",
    "            image_path = os.path.join(class_input_path, image_name)\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is None:\n",
    "                continue\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image = cv2.resize(image, (224, 224))\n",
    "\n",
    "            save_path = os.path.join(class_output_path, f\"orig_{image_name}\")\n",
    "            cv2.imwrite(save_path, cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "        num_needed = target_count - num_original\n",
    "        print(f\"🔹 Generating {num_needed} augmented images.\")\n",
    "\n",
    "        aug_count = 0\n",
    "        while aug_count < num_needed:\n",
    "            for image_name in images:\n",
    "                image_path = os.path.join(class_input_path, image_name)\n",
    "                image = cv2.imread(image_path)\n",
    "                if image is None:\n",
    "                    continue\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                image = cv2.resize(image, (224, 224))\n",
    "\n",
    "                num_augmentations = random.randint(1, 3)\n",
    "                chosen_augmentations = random.sample(AUGMENTATIONS, num_augmentations)\n",
    "\n",
    "                aug_image = image.astype(np.float32) / 255.0\n",
    "                for aug_func in chosen_augmentations:\n",
    "                    aug_image = aug_func(aug_image)\n",
    "\n",
    "                aug_image = (aug_image * 255).astype(np.uint8)\n",
    "\n",
    "                save_path = os.path.join(class_output_path, f\"aug_{aug_count}_{image_name}\")\n",
    "                cv2.imwrite(save_path, cv2.cvtColor(aug_image, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "                aug_count += 1\n",
    "                if aug_count >= num_needed:\n",
    "                    break\n",
    "\n",
    "        print(f\"✅ Class '{class_name}' in '{split}' now contains {target_count} images.\")\n",
    "\n",
    "print(\"🎉 Data augmentation for train and val complete!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coffe_leaf_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
