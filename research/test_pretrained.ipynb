{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "5p7HOikvMjLJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1600640-8889-48fc-aa55-6f1536d508a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'AIVNRG-242-T13'...\n",
            "remote: Enumerating objects: 479, done.\u001b[K\n",
            "remote: Counting objects: 100% (35/35), done.\u001b[K\n",
            "remote: Compressing objects: 100% (29/29), done.\u001b[K\n",
            "remote: Total 479 (delta 8), reused 29 (delta 6), pack-reused 444 (from 1)\u001b[K\n",
            "Receiving objects: 100% (479/479), 92.19 MiB | 14.67 MiB/s, done.\n",
            "Resolving deltas: 100% (38/38), done.\n",
            "Updating files: 100% (408/408), done.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/baok3/AIVNRG-242-T13.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd AIVNRG-242-T13/data/splits/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVZnmXPl3Mie",
        "outputId": "636bed12-be2d-4c30-a550-f37f72bc9c22"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/AIVNRG-242-T13/data/splits\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Trainer\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from typing import Dict, List, Tuple, Any\n",
        "\n",
        "# Utils\n",
        "import os\n",
        "import json\n",
        "from datetime import datetime\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "gK5aUJ5A3dXu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelTrainer:\n",
        "    def __init__(\n",
        "        self,\n",
        "        models_dict: Dict[str, nn.Module],\n",
        "        train_loader: DataLoader,\n",
        "        test_loader: DataLoader,\n",
        "        criterion: nn.Module,\n",
        "        num_epochs: int = 10,\n",
        "        device: str = None\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Initialize the model trainer with multiple models and dataset loaders.\n",
        "\n",
        "        Args:\n",
        "            models_dict: Dictionary of model names and their instances\n",
        "            train_loader: Training data loader\n",
        "            test_loader: Test data loader\n",
        "            criterion: Loss function\n",
        "            num_epochs: Number of training epochs\n",
        "            device: Device to run training on (will auto-detect if None)\n",
        "        \"\"\"\n",
        "        self.device = device or ('cpu')\n",
        "        self.models = {name: model.to(self.device) for name, model in models_dict.items()}\n",
        "        self.train_loader = train_loader\n",
        "        self.test_loader = test_loader\n",
        "        self.criterion = criterion\n",
        "        self.num_epochs = num_epochs\n",
        "        self.results = {}\n",
        "\n",
        "    def _validate_input_batch(self, inputs: torch.Tensor, labels: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"Validate and prepare input batch for training/testing.\"\"\"\n",
        "        if not isinstance(inputs, torch.Tensor):\n",
        "            raise TypeError(f\"Expected inputs to be torch.Tensor, got {type(inputs)}\")\n",
        "        if not isinstance(labels, torch.Tensor):\n",
        "            raise TypeError(f\"Expected labels to be torch.Tensor, got {type(labels)}\")\n",
        "\n",
        "        return inputs.to(self.device), labels.to(self.device)\n",
        "\n",
        "    def train_model(self, model_name: str, learning_rate: float = 0.001) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Train a single model and track its performance metrics.\n",
        "\n",
        "        Args:\n",
        "            model_name: Name of the model to train\n",
        "            learning_rate: Learning rate for optimization\n",
        "\n",
        "        Returns:\n",
        "            Dictionary containing training history\n",
        "        \"\"\"\n",
        "        if model_name not in self.models:\n",
        "            raise ValueError(f\"Model {model_name} not found in initialized models\")\n",
        "\n",
        "        model = self.models[model_name]\n",
        "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "        history = {\n",
        "            'train_loss': [],\n",
        "            'train_acc': [],\n",
        "            'val_loss': [],\n",
        "            'val_acc': [],\n",
        "            'test_metrics': None\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            for epoch in range(self.num_epochs):\n",
        "                # Training phase\n",
        "                model.train()\n",
        "                train_loss = 0\n",
        "                correct = 0\n",
        "                total = 0\n",
        "\n",
        "                for batch_idx, (inputs, labels) in enumerate(self.train_loader):\n",
        "                    try:\n",
        "                        inputs, labels = self._validate_input_batch(inputs, labels)\n",
        "\n",
        "                        optimizer.zero_grad()\n",
        "                        outputs = model(inputs)\n",
        "                        loss = self.criterion(outputs, labels)\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                        train_loss += loss.item()\n",
        "                        _, predicted = outputs.max(1)\n",
        "                        total += labels.size(0)\n",
        "                        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "                    except RuntimeError as e:\n",
        "                        print(f\"Error in batch {batch_idx}: {str(e)}\")\n",
        "                        continue\n",
        "\n",
        "                train_acc = 100. * correct / total\n",
        "                train_loss = train_loss / len(self.train_loader)\n",
        "\n",
        "                # Validation phase\n",
        "                val_loss, val_acc = self._validate_epoch(model)\n",
        "\n",
        "                # Save metrics\n",
        "                history['train_loss'].append(train_loss)\n",
        "                history['train_acc'].append(train_acc)\n",
        "                history['val_loss'].append(val_loss)\n",
        "                history['val_acc'].append(val_acc)\n",
        "\n",
        "                print(f'Epoch [{epoch+1}/{self.num_epochs}] - '\n",
        "                      f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, '\n",
        "                      f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Training interrupted for {model_name}: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "        # Final test phase\n",
        "        history['test_metrics'] = self.test(model)\n",
        "        self.results[model_name] = history\n",
        "        return history\n",
        "\n",
        "    def _validate_epoch(self, model: nn.Module) -> Tuple[float, float]:\n",
        "        \"\"\"Run validation for one epoch.\"\"\"\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in self.test_loader:\n",
        "                inputs, labels = self._validate_input_batch(inputs, labels)\n",
        "                outputs = model(inputs)\n",
        "                loss = self.criterion(outputs, labels)\n",
        "\n",
        "                val_loss += loss.item()\n",
        "                _, predicted = outputs.max(1)\n",
        "                total += labels.size(0)\n",
        "                correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        return val_loss / len(self.test_loader), 100. * correct / total\n",
        "\n",
        "    def test(self, model: nn.Module) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Test model and return metrics\n",
        "\n",
        "        Returns:\n",
        "            Dictionary containing test metrics\n",
        "        \"\"\"\n",
        "        model.eval()\n",
        "        test_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        predictions = []\n",
        "        targets = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (inputs, labels) in enumerate(self.test_loader):\n",
        "                try:\n",
        "                    inputs, labels = self._validate_input_batch(inputs, labels)\n",
        "\n",
        "                    outputs = model(inputs)\n",
        "                    loss = self.criterion(outputs, labels)\n",
        "                    test_loss += loss.item()\n",
        "\n",
        "                    _, predicted = outputs.max(1)  # Multi-class case\n",
        "                    predictions.append(predicted.cpu().numpy())\n",
        "                    targets.append(labels.cpu().numpy())\n",
        "\n",
        "                    total += labels.size(0)\n",
        "                    correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "                except RuntimeError as e:\n",
        "                    print(f\"Error in batch {batch_idx}: {str(e)}\")\n",
        "                    continue\n",
        "\n",
        "        # Flatten predictions and targets for metrics\n",
        "        all_predictions = np.concatenate(predictions)\n",
        "        all_targets = np.concatenate(targets)\n",
        "\n",
        "        test_acc = 100. * correct / total\n",
        "        return {\n",
        "            'test_loss': test_loss / len(self.test_loader),\n",
        "            'test_accuracy': test_acc,\n",
        "            'predictions': all_predictions,\n",
        "            'targets': all_targets\n",
        "        }\n",
        "\n",
        "    def train_all_models(self) -> None:\n",
        "        \"\"\"Train all models and save results\"\"\"\n",
        "        for model_name in self.models:\n",
        "            try:\n",
        "                self.train_model(model_name)\n",
        "            except Exception as e:\n",
        "                print(f\"Failed to train {model_name}: {str(e)}\")\n",
        "                continue\n",
        "\n",
        "        self.save_results()\n",
        "        self.generate_reports()\n",
        "\n",
        "    def save_results(self) -> None:\n",
        "        \"\"\"Save training results to CSV\"\"\"\n",
        "        results_df = pd.DataFrame()\n",
        "\n",
        "        for model_name, history in self.results.items():\n",
        "            model_df = pd.DataFrame({\n",
        "                'epoch': range(1, self.num_epochs + 1),\n",
        "                'model': model_name,\n",
        "                'train_loss': history['train_loss'],\n",
        "                'train_acc': history['train_acc'],\n",
        "                'val_loss': history['val_loss'],\n",
        "                'val_acc': history['val_acc']\n",
        "            })\n",
        "            results_df = pd.concat([results_df, model_df])\n",
        "\n",
        "        os.makedirs('results', exist_ok=True)\n",
        "        results_df.to_csv('results/training_results.csv', index=False)\n",
        "\n",
        "    def generate_reports(self) -> None:\n",
        "        \"\"\"Generate and save visualization plots\"\"\"\n",
        "        os.makedirs('plots', exist_ok=True)\n",
        "\n",
        "        self._plot_training_curves()\n",
        "        self._plot_confusion_matrices()\n",
        "        self._plot_model_comparison()\n",
        "        self._analyze_fitting()\n",
        "\n",
        "    def _plot_training_curves(self) -> None:\n",
        "        \"\"\"Plot training and validation curves for all models\"\"\"\n",
        "        plt.figure(figsize=(15, 10))\n",
        "\n",
        "        for model_name, history in self.results.items():\n",
        "            epochs = range(1, self.num_epochs + 1)\n",
        "\n",
        "            # Loss subplot\n",
        "            plt.subplot(2, 1, 1)\n",
        "            plt.plot(epochs, history['train_loss'], '-o', label=f'{model_name} (train)')\n",
        "            plt.plot(epochs, history['val_loss'], '--o', label=f'{model_name} (val)')\n",
        "            plt.title('Model Loss')\n",
        "            plt.xlabel('Epoch')\n",
        "            plt.ylabel('Loss')\n",
        "            plt.legend()\n",
        "\n",
        "            # Accuracy subplot\n",
        "            plt.subplot(2, 1, 2)\n",
        "            plt.plot(epochs, history['train_acc'], '-o', label=f'{model_name} (train)')\n",
        "            plt.plot(epochs, history['val_acc'], '--o', label=f'{model_name} (val)')\n",
        "            plt.title('Model Accuracy')\n",
        "            plt.xlabel('Epoch')\n",
        "            plt.ylabel('Accuracy (%)')\n",
        "            plt.legend()\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('plots/training_curves.png')\n",
        "        plt.close()\n",
        "\n",
        "    def _plot_confusion_matrices(self) -> None:\n",
        "        \"\"\"Plot confusion matrices for all models\"\"\"\n",
        "        for model_name, history in self.results.items():\n",
        "            metrics = history['test_metrics']\n",
        "            cm = confusion_matrix(metrics['targets'], metrics['predictions'])\n",
        "\n",
        "            plt.figure(figsize=(10, 8))\n",
        "            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "            plt.title(f'Confusion Matrix - {model_name}')\n",
        "            plt.xlabel('Predicted')\n",
        "            plt.ylabel('True')\n",
        "            plt.savefig(f'plots/confusion_matrix_{model_name}.png')\n",
        "            plt.close()\n",
        "\n",
        "    def _plot_model_comparison(self) -> None:\n",
        "        \"\"\"Plot final test accuracy comparison\"\"\"\n",
        "        model_names = list(self.results.keys())\n",
        "        test_accuracies = [self.results[model]['test_metrics']['test_accuracy']\n",
        "                          for model in model_names]\n",
        "\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        bars = plt.bar(model_names, test_accuracies)\n",
        "        plt.title('Model Comparison - Test Accuracy')\n",
        "        plt.xlabel('Model')\n",
        "        plt.ylabel('Test Accuracy (%)')\n",
        "        plt.xticks(rotation=45)\n",
        "\n",
        "        # Add value labels on top of each bar\n",
        "        for bar in bars:\n",
        "            height = bar.get_height()\n",
        "            plt.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                    f'{height:.1f}%',\n",
        "                    ha='center', va='bottom')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('plots/model_comparison.png')\n",
        "        plt.close()\n",
        "\n",
        "    def _analyze_fitting(self) -> None:\n",
        "        \"\"\"Analyze and report fitting status for each model\"\"\"\n",
        "        fitting_analysis = {}\n",
        "\n",
        "        for model_name, history in self.results.items():\n",
        "            train_loss = history['train_loss']\n",
        "            val_loss = history['val_loss']\n",
        "\n",
        "            # Calculate metrics for fitting analysis\n",
        "            final_train_loss = train_loss[-1]\n",
        "            final_val_loss = val_loss[-1]\n",
        "            loss_gap = final_val_loss - final_train_loss\n",
        "\n",
        "            # Determine fitting status\n",
        "            if final_train_loss > 0.1 and final_val_loss > 0.1:\n",
        "                status = \"Underfitting\"\n",
        "            elif loss_gap > 0.1:\n",
        "                status = \"Overfitting\"\n",
        "            else:\n",
        "                status =  \"Fit\"\n",
        "\n",
        "            fitting_analysis[model_name] = {\n",
        "                'status': status,\n",
        "                'final_train_loss': final_train_loss,\n",
        "                'final_val_loss': final_val_loss,\n",
        "                'loss_gap': loss_gap,\n",
        "                'recommended_action': self._get_fitting_recommendation(status)\n",
        "            }\n",
        "\n",
        "        with open('results/fitting_analysis.json', 'w') as f:\n",
        "            json.dump(fitting_analysis, f, indent=4)\n",
        "\n",
        "    def _get_fitting_recommendation(self, status: str) -> str:\n",
        "        \"\"\"Get recommendation based on fitting status\"\"\"\n",
        "        recommendations = {\n",
        "            \"Underfitting\": \"Consider increasing model capacity or training longer\",\n",
        "            \"Overfitting\": \"Consider adding regularization or reducing model capacity\",\n",
        "            \"Fit\": \"Model is well-balanced, continue monitoring performance\"\n",
        "        }\n",
        "        return recommendations.get(status, \"Unknown fitting status\")"
      ],
      "metadata": {
        "id": "jj7Elisb3W_o"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms, models, datasets\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Load train dataset\n",
        "train_dataset = datasets.ImageFolder('train', transform=transform)\n",
        "\n",
        "# Load test dataset\n",
        "test_dataset = datasets.ImageFolder('test', transform=transform)\n"
      ],
      "metadata": {
        "id": "d7XatJoR3tEn"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_labels = len(train_dataset.classes)\n",
        "print(num_labels)\n",
        "\n",
        "def EfficientNet():\n",
        "    model = models.efficientnet_b0(pretrained=True)\n",
        "    model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_labels)\n",
        "    return model.to(device)\n",
        "\n",
        "def ResNet50():\n",
        "    model = models.resnet50(pretrained=True)\n",
        "    model.fc = nn.Linear(model.fc.in_features, num_labels)\n",
        "    return model.to(device)\n",
        "\n",
        "def VGG16():\n",
        "    model = models.vgg16(pretrained=True)\n",
        "    model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_labels)\n",
        "    return model.to(device)\n",
        "\n",
        "def MobileNet():\n",
        "    model = models.mobilenet_v2(pretrained=True)\n",
        "    model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_labels)\n",
        "    return model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luZ6MwNR32B-",
        "outputId": "b5f71df6-cf1f-4404-bd76-74a187cd7c97"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "models = {\n",
        "    \"EfficientNet\": EfficientNet(),\n",
        "    \"ResNet50\": ResNet50(),\n",
        "    \"VGG16\": VGG16(),\n",
        "    \"MobileNet\": MobileNet()\n",
        "}\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zhRc3ZG33_P",
        "outputId": "2e17fc37-3071-4a74-ca1a-10a5810f4b05"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 153MB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:04<00:00, 111MB/s] \n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth\n",
            "100%|██████████| 13.6M/13.6M [00:00<00:00, 102MB/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "trainer = ModelTrainer(models, train_loader, test_loader, criterion, num_epochs=3)\n",
        "trainer.train_all_models()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t849qh5V3_vO",
        "outputId": "52520d35-eeb5-4049-cc1c-7e3041f2e4e3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/3] - Train Loss: 0.1048, Train Acc: 97.92%, Val Loss: 0.0008, Val Acc: 100.00%\n",
            "Epoch [2/3] - Train Loss: 0.0302, Train Acc: 98.75%, Val Loss: 0.0002, Val Acc: 100.00%\n",
            "Epoch [3/3] - Train Loss: 0.0108, Train Acc: 100.00%, Val Loss: 0.0010, Val Acc: 100.00%\n",
            "Epoch [1/3] - Train Loss: 0.5829, Train Acc: 72.08%, Val Loss: 48.2559, Val Acc: 50.00%\n",
            "Epoch [2/3] - Train Loss: 0.1253, Train Acc: 95.00%, Val Loss: 75.3728, Val Acc: 50.00%\n",
            "Epoch [3/3] - Train Loss: 0.0686, Train Acc: 97.50%, Val Loss: 158.8124, Val Acc: 50.00%\n",
            "Epoch [1/3] - Train Loss: 2.1577, Train Acc: 43.33%, Val Loss: 0.6799, Val Acc: 66.67%\n",
            "Epoch [2/3] - Train Loss: 1.1739, Train Acc: 52.50%, Val Loss: 0.7054, Val Acc: 50.00%\n",
            "Epoch [3/3] - Train Loss: 0.7075, Train Acc: 55.83%, Val Loss: 0.8567, Val Acc: 50.00%\n",
            "Epoch [1/3] - Train Loss: 0.1477, Train Acc: 92.50%, Val Loss: 0.0008, Val Acc: 100.00%\n",
            "Epoch [2/3] - Train Loss: 0.0187, Train Acc: 98.75%, Val Loss: 0.0003, Val Acc: 100.00%\n",
            "Epoch [3/3] - Train Loss: 0.0111, Train Acc: 99.17%, Val Loss: 0.2241, Val Acc: 83.33%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.test(models['EfficientNet'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4pyIXBSFt0O",
        "outputId": "da32cb2e-066a-42fb-8c8c-de8b5eee059d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'test_loss': 0.0010463363723829389,\n",
              " 'test_accuracy': 100.0,\n",
              " 'predictions': array([0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]),\n",
              " 'targets': array([0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1])}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.test(models['ResNet50'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_IBbibRBF4-9",
        "outputId": "d203b58c-6632-4fd5-c810-17c79b25e358"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'test_loss': 158.81239318847656,\n",
              " 'test_accuracy': 50.0,\n",
              " 'predictions': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " 'targets': array([0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1])}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.test(models['VGG16'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZQXMT0GGB5d",
        "outputId": "3c5c6d99-85f5-488b-bee9-995b8506c8df"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'test_loss': 0.8567495942115784,\n",
              " 'test_accuracy': 50.0,\n",
              " 'predictions': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
              " 'targets': array([0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1])}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.test(models['MobileNet'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIPdpLqeGGTO",
        "outputId": "cabd6a1a-bca0-4aa3-8651-1938385e7f84"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'test_loss': 0.2240956574678421,\n",
              " 'test_accuracy': 83.33333333333333,\n",
              " 'predictions': array([0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " 'targets': array([0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1])}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer._plot_training_curves()"
      ],
      "metadata": {
        "id": "k-_MJVxpGQ3Q"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_results()"
      ],
      "metadata": {
        "id": "HfOT2ufcBqWA"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.generate_reports()"
      ],
      "metadata": {
        "id": "pZ5bQTHsCJdY"
      },
      "execution_count": 15,
      "outputs": []
    }
  ]
}