{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import hashlib\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import quote\n",
    "import logging\n",
    "from typing import List, Set\n",
    "import time\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Downloaded bing_ad1aa30f4820d15457e552a6c99ac6de.jpg\n",
      "INFO:__main__:Downloaded bing_0fcdae9f483bf7c75d0ced7290b0832d.jpg\n",
      "INFO:__main__:Downloaded bing_d945f89d70f648ee959e07c3c7bba556.jpg\n",
      "INFO:__main__:Downloaded bing_6317a9e1b8d1ab139f7f8731d1f1c287.jpg\n",
      "INFO:__main__:Downloaded bing_22e54241043976b87c154ff54eeaa6ac.jpg\n",
      "INFO:__main__:Downloaded bing_791338a827d60b368f625a785e389c6d.jpg\n",
      "INFO:__main__:Downloaded bing_1a1dad14b11b4089a06fa8efd5944939.jpg\n",
      "INFO:__main__:Downloaded bing_d3456f947594cb37cb346c186f0192ed.jpg\n",
      "INFO:__main__:Downloaded bing_8655c0cfd2275bd1262c2bb57513c484.jpg\n",
      "INFO:__main__:Downloaded bing_198b0562f52c14e57487b34b399fa54d.jpg\n",
      "INFO:__main__:Downloaded bing_d41c883e4794335c122012323eeecf39.jpg\n",
      "INFO:__main__:Downloaded bing_cf85cda72428022c32cb96dae4987916.jpg\n",
      "INFO:__main__:Downloaded bing_b7c3a3299fda99428d46af1e013811a0.jpg\n",
      "INFO:__main__:Downloaded bing_6fddafe4504ee2373d9c1e33c30923e1.jpg\n",
      "INFO:__main__:Downloaded bing_95745f62853b32377e9b34e14e761589.jpg\n",
      "INFO:__main__:Downloaded bing_7c2378ed904b9611ab3ae313182981d9.jpg\n",
      "INFO:__main__:Downloaded bing_0b4114f5039cd7b0309a1d9a6f23bc68.jpg\n",
      "INFO:__main__:Downloaded bing_7352077929629d2286d0d2b6410c65bb.jpg\n",
      "INFO:__main__:Downloaded bing_29c1291118cea06242458e920666e6e8.jpg\n",
      "INFO:__main__:Downloaded bing_230e7e3612f3e0c29da863198d34b672.jpg\n",
      "INFO:__main__:Downloaded bing_83c7b9dcda5aa30cc1839517772ba285.jpg\n",
      "INFO:__main__:Downloaded bing_758d7518be72b1f6886eaa87931a86f4.jpg\n",
      "INFO:__main__:Downloaded bing_27b27b1f6f93475644eb1292f64039b3.jpg\n",
      "INFO:__main__:Downloaded bing_4e1f957760af2481be1e8c3863d39532.jpg\n",
      "INFO:__main__:Downloaded bing_45d9ac7c0b647f1ee51c27a71391b883.jpg\n",
      "INFO:__main__:Downloaded bing_184a4fa27d7d4437faab7501ad284ec6.jpg\n"
     ]
    }
   ],
   "source": [
    "class AsyncImageScraper:\n",
    "    def __init__(self, output_dir: str, max_images: int = 1000):\n",
    "        self.output_dir = output_dir\n",
    "        self.max_images = max_images\n",
    "        self.downloaded_count = 0\n",
    "        self.seen_urls: Set[str] = set()\n",
    "        self.session = None\n",
    "        \n",
    "        # Setup logging\n",
    "        logging.basicConfig(level=logging.INFO)\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        \n",
    "        # Create output directory\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    async def init_session(self):\n",
    "        if not self.session:\n",
    "            self.session = aiohttp.ClientSession()\n",
    "\n",
    "    async def close_session(self):\n",
    "        if self.session:\n",
    "            await self.session.close()\n",
    "            self.session = None\n",
    "\n",
    "    async def download_image(self, url: str, source: str) -> bool:\n",
    "        if url in self.seen_urls:\n",
    "            return False\n",
    "            \n",
    "        self.seen_urls.add(url)\n",
    "        try:\n",
    "            async with self.session.get(url, timeout=30) as response:\n",
    "                if response.status == 200:\n",
    "                    content = await response.read()\n",
    "                    file_hash = hashlib.md5(url.encode()).hexdigest()\n",
    "                    filename = f\"{source}_{file_hash}.jpg\"\n",
    "                    filepath = os.path.join(self.output_dir, filename)\n",
    "                    \n",
    "                    with open(filepath, 'wb') as f:\n",
    "                        f.write(content)\n",
    "                    \n",
    "                    self.downloaded_count += 1\n",
    "                    self.logger.info(f\"Downloaded {filename}\")\n",
    "                    return True\n",
    "                    \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error downloading {url}: {e}\")\n",
    "        return False\n",
    "\n",
    "    async def scrape_bing(self, query: str):\n",
    "        encoded_query = quote(query)\n",
    "        url = f\"https://www.bing.com/images/search?q={encoded_query}\"\n",
    "        \n",
    "        try:\n",
    "            async with self.session.get(url) as response:\n",
    "                if response.status == 200:\n",
    "                    html = await response.text()\n",
    "                    soup = BeautifulSoup(html, 'html.parser')\n",
    "                    images = soup.find_all('img', {'class': 'mimg'})\n",
    "                    \n",
    "                    for img in images:\n",
    "                        if self.downloaded_count >= self.max_images:\n",
    "                            break\n",
    "                            \n",
    "                        image_url = img.get('src')\n",
    "                        if image_url:\n",
    "                            await self.download_image(image_url, 'bing')\n",
    "                            await asyncio.sleep(1)\n",
    "                            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error scraping Bing: {e}\")\n",
    "\n",
    "    async def scrape_shutterstock(self, query: str):\n",
    "        encoded_query = quote(query)\n",
    "        url = f\"https://www.shutterstock.com/search/{encoded_query}\"\n",
    "        \n",
    "        try:\n",
    "            async with self.session.get(url) as response:\n",
    "                if response.status == 200:\n",
    "                    html = await response.text()\n",
    "                    soup = BeautifulSoup(html, 'html.parser')\n",
    "                    images = soup.find_all('img', {'data-testid': 'asset-image'})\n",
    "                    \n",
    "                    for img in images:\n",
    "                        if self.downloaded_count >= self.max_images:\n",
    "                            break\n",
    "                            \n",
    "                        image_url = img.get('src')\n",
    "                        if image_url:\n",
    "                            await self.download_image(image_url, 'shutterstock')\n",
    "                            await asyncio.sleep(1)\n",
    "                            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error scraping Shutterstock: {e}\")\n",
    "\n",
    "    async def scrape_all(self, search_terms: List[str]):\n",
    "        await self.init_session()\n",
    "        try:\n",
    "            for term in search_terms:\n",
    "                if self.downloaded_count >= self.max_images:\n",
    "                    break\n",
    "                    \n",
    "                tasks = [\n",
    "                    self.scrape_bing(term),\n",
    "                    self.scrape_shutterstock(term)\n",
    "                ]\n",
    "                await asyncio.gather(*tasks)\n",
    "                \n",
    "        finally:\n",
    "            await self.close_session()\n",
    "\n",
    "# Usage\n",
    "async def main():\n",
    "    search_terms = [\n",
    "        'pink disease on coffee leaf',\n",
    "        'bệnh nấm hồng cây cà phê'\n",
    "    ]\n",
    "    \n",
    "    scraper = AsyncImageScraper('pink_disease_images')\n",
    "    await scraper.scrape_all(search_terms)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
