{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import re\n",
    "import json\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Define headers and search parameters\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/103.0.5060.114 Safari/537.36\"\n",
    "}\n",
    "\n",
    "params = {\n",
    "    \"q\": \"bệnh huyết trùng trên lá cà phê\",  # Search query\n",
    "    \"tbm\": \"isch\",                         # Image search\n",
    "    \"hl\": \"vn\",                            # Language\n",
    "    \"gl\": \"vn\",                            # Country\n",
    "    \"ijn\": \"0\"                             # Page number\n",
    "}\n",
    "\n",
    "def create_folder(folder_path):\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "\n",
    "def download_images(images, folder_path, max_images=100):\n",
    "    for index, img_url in enumerate(images[:max_images], start=1):\n",
    "        try:\n",
    "            print(f\"Downloading image {index}/{max_images}...\")\n",
    "            image_path = os.path.join(folder_path, f\"youtube_{index}.jpg\")\n",
    "            urllib.request.urlretrieve(img_url, image_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to download image {index}: {e}\")\n",
    "\n",
    "def scrape_google_images(params, headers, folder_path, max_images=100):\n",
    "    response = requests.get(\"https://www.bing.com/search\", params=params, headers=headers, timeout=30)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    # Extract image URLs using regex\n",
    "    scripts = soup.find_all(\"script\")\n",
    "    image_data = \"\".join(re.findall(r\"AF_initDataCallback\\(([^<]+)\\);\", str(scripts)))\n",
    "    image_data_json = json.loads(json.dumps(image_data))  # Ensure JSON compatibility\n",
    "\n",
    "    # Full-resolution image URLs\n",
    "    image_urls = re.findall(r\"(https?://[^,]+?\\.(?:jpg|png|gif))\", image_data_json)\n",
    "    \n",
    "    # Create folder and download images\n",
    "    create_folder(folder_path)\n",
    "    download_images(image_urls, folder_path, max_images)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    output_folder = \"nematode_disease_in_coffee_leaf_images\"\n",
    "    scrape_google_images(params, headers, output_folder, max_images=100)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
