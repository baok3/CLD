import streamlit as st
import torch
import torch.nn as nn
import torchvision.transforms as transforms
from torchvision import datasets, models
from PIL import Image
import os
import random
import torch.nn.functional as F  # For softmax

# ƒê·ªãnh nghƒ©a thi·∫øt b·ªã
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ƒê∆∞·ªùng d·∫´n dataset & m√¥ h√¨nh
DATASET_PATH = "E:\\data_optimize\\train_fewshot"
MODEL_PATH = "E:/Model save/Deep_learning_model/efficientnet_coffee.pth"

# Load dataset ƒë·ªÉ l·∫•y danh s√°ch class
train_dataset = datasets.ImageFolder(root=DATASET_PATH)
class_labels = train_dataset.classes

# H√†m load m√¥ h√¨nh v·ªõi ƒë∆∞·ªùng d·∫´n ƒë√£ ch·ªâ ƒë·ªãnh
@st.cache_resource
def load_model():
    model = models.efficientnet_b0(pretrained=False)  # Kh√¥ng t·∫£i pretrained weights
    num_ftrs = model.classifier[1].in_features
    model.classifier[1] = nn.Linear(num_ftrs, len(class_labels))  # Thay ƒë·ªïi s·ªë l·ªõp ƒë·∫ßu ra c·ªßa classifier
    model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))  # Load tr·ªçng s·ªë m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán
    return model.to(DEVICE).eval()  # Chuy·ªÉn m√¥ h√¨nh sang ch·∫ø ƒë·ªô eval (d·ª± ƒëo√°n)

# Load m√¥ h√¨nh ban ƒë·∫ßu (m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán tr∆∞·ªõc)
model = load_model()

# Chu·∫©n h√≥a ·∫£nh
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # D√πng chu·∫©n h√≥a ImageNet
])

# **Giao di·ªán App Ch√≠nh**
st.title("üåø ·ª®ng D·ª•ng Nh·∫≠n Di·ªán B·ªánh L√° C√† Ph√™")
st.write("Ch·ª•p ·∫£nh ho·∫∑c t·∫£i ·∫£nh l√™n ƒë·ªÉ d·ª± ƒëo√°n b·ªánh.")

# **T·∫£i ·∫£nh l√™n**
uploaded_file = st.file_uploader("üì∏ T·∫£i ·∫£nh l√™n ƒë·ªÉ ph√¢n lo·∫°i", type=["png", "jpg", "jpeg"])

if uploaded_file is not None:
    image = Image.open(uploaded_file).convert("RGB")
    st.image(image, caption="üì∑ ·∫¢nh ƒë√£ t·∫£i l√™n", use_container_width=True)

    # Ti·ªÅn x·ª≠ l√Ω ·∫£nh
    img_tensor = transform(image).unsqueeze(0).to(DEVICE)

    # D·ª± ƒëo√°n v·ªõi m√¥ h√¨nh
    with torch.no_grad():
        output = model(img_tensor)
        predicted_class = torch.argmax(output, dim=1).item()

        # Apply softmax to get the confidence scores
        probabilities = F.softmax(output, dim=1)
        confidence_score = probabilities[0][predicted_class].item() * 100  # Multiply by 100 to get percentage

    st.write(f"üîç K·∫øt qu·∫£ d·ª± ƒëo√°n: **{class_labels[predicted_class]}**")
    st.write(f"üìä Confidence Score: **{confidence_score:.2f}%**")

# **Ch·ª©c nƒÉng Few-Shot Learning**
with st.expander("üéØ Few-Shot Learning - Th√™m L·ªõp M·ªõi"):
    # B∆∞·ªõc 1: T·∫£i ·∫£nh l√™n tr∆∞·ªõc
    uploaded_files = st.file_uploader("üì∏ T·∫£i l√™n 5 ·∫£nh cho l·ªõp m·ªõi", type=["png", "jpg", "jpeg"], accept_multiple_files=True)

    if uploaded_files and len(uploaded_files) == 5:
        st.success("‚úÖ ƒê√£ t·∫£i l√™n ƒë·ªß 5 ·∫£nh! H√£y ƒë·∫∑t t√™n cho l·ªõp m·ªõi.")

        # B∆∞·ªõc 2: Nh·∫≠p t√™n l·ªõp m·ªõi sau khi ƒë√£ t·∫£i ·∫£nh l√™n
        new_class_name = st.text_input("üÜï Nh·∫≠p t√™n l·ªõp b·ªánh m·ªõi v√† nh·∫•n ENTER")

        if new_class_name:
            new_class_folder = os.path.join(DATASET_PATH, new_class_name)  # L∆∞u tr·ª±c ti·∫øp v√†o dataset g·ªëc
            os.makedirs(new_class_folder, exist_ok=True)

            # L∆∞u ·∫£nh v√†o th∆∞ m·ª•c m·ªõi
            for i, file in enumerate(uploaded_files):
                img_path = os.path.join(new_class_folder, f"image_{i+1}.jpg")
                with open(img_path, "wb") as f:
                    f.write(file.getbuffer())
            st.success(f"‚úÖ ƒê√£ l∆∞u 5 ·∫£nh cho l·ªõp {new_class_name}!")

            # C·∫≠p nh·∫≠t danh s√°ch l·ªõp
            class_labels.append(new_class_name)

            # **Fine-tune m√¥ h√¨nh v·ªõi Few-Shot Learning**
            if st.button("üöÄ Train Few-Shot Model"):
                st.info("üîÑ ƒêang hu·∫•n luy·ªán m√¥ h√¨nh v·ªõi l·ªõp m·ªõi...")

                # Load l·∫°i dataset
                combined_dataset = datasets.ImageFolder(root=DATASET_PATH)
                class_indices = {cls: [i for i, (img, label) in enumerate(combined_dataset.samples) if label == cls] for cls in range(len(class_labels))}

                # Fine-tune m√¥ h√¨nh
                def fine_tune_with_fewshot(model, dataset, class_indices, n_epochs=10):
                    optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)  # Gi·∫£m learning rate ƒë·ªÉ tr√°nh overfitting
                    model.train()

                    for epoch in range(n_epochs):
                        total_loss = 0
                        for _ in range(5):  # 5 episodes m·ªói epoch
                            # T·∫°o episode ng·∫´u nhi√™n t·ª´ c√°c l·ªõp c√≥ ƒë·ªß ·∫£nh h·ªó tr·ª£
                            sampled_classes = random.sample(list(class_indices.keys()), len(class_indices))

                            support_imgs, query_imgs, support_labels, query_labels = [], [], [], []

                            # L·ªçc ra c√°c l·ªõp c√≥ ƒë·ªß √≠t nh·∫•t 3 ·∫£nh h·ªó tr·ª£
                            sampled_classes = [cls for cls in sampled_classes if len(class_indices[cls]) >= 3]

                            for new_label, class_id in enumerate(sampled_classes):
                                indices = class_indices[class_id]
                                sampled_indices = random.sample(indices, min(10, len(indices)))

                                # L·∫•y 3 ·∫£nh h·ªó tr·ª£ v√† ph·∫ßn c√≤n l·∫°i l√†m query
                                support_imgs += [dataset[i][0] for i in sampled_indices[:3]]
                                query_imgs += [dataset[i][0] for i in sampled_indices[3:]]
                                support_labels += [new_label] * 3
                                query_labels += [new_label] * (len(sampled_indices) - 3)

                            # √Åp d·ª•ng transform v√† chuy·ªÉn ƒë·ªïi sang tensor tr∆∞·ªõc khi s·ª≠ d·ª•ng torch.stack
                            support_imgs = torch.stack([transform(img).to(DEVICE) for img in support_imgs])
                            query_imgs = torch.stack([transform(img).to(DEVICE) for img in query_imgs])

                            # T√≠nh embeddings
                            support_emb = model(support_imgs)
                            query_emb = model(query_imgs)

                            # T√≠nh prototypes t·ª´ support_emb
                            prototypes = support_emb.view(len(sampled_classes), 3, -1).mean(dim=1)
                            distances = torch.cdist(query_emb, prototypes)

                            # T·∫°o labels cho ·∫£nh query
                            labels = torch.tensor(query_labels).to(DEVICE)

                            # T√≠nh loss
                            loss = nn.CrossEntropyLoss()(distances, labels)

                            optimizer.zero_grad()
                            loss.backward()
                            optimizer.step()
                            total_loss += loss.item()

                        st.write(f"üîÑ Epoch [{epoch+1}/{n_epochs}], Loss: {total_loss/5:.4f}")

                fine_tune_with_fewshot(model, combined_dataset, class_indices)

                # L∆∞u l·∫°i m√¥ h√¨nh sau khi fine-tuning
                torch.save(model.state_dict(), "E:/Model save/Deep_learning_model/efficientnet_fewshot.pth")
                st.success("‚úÖ M√¥ h√¨nh ƒë√£ h·ªçc l·ªõp m·ªõi th√†nh c√¥ng!")